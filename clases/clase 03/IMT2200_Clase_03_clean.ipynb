{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 20px; width: 200px\" src=\"https://raw.githubusercontent.com/raxlab/imt2200-data/main/media/logo.jpg\">  IMT 2200 - Introducción a Ciencia de Datos\n",
    "**Pontificia Universidad Católica de Chile**<br>\n",
    "**Instituto de Ingeniería Matemática y Computacional**<br>\n",
    "**Semestre 2025-S2**<br>\n",
    "**Profesor:** Rodrigo A. Carrasco <br>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1><center>Clase 03: Trabajo con Datos Estructurados</center></h1>\n",
    "\n",
    "Este ejercicio busca que los estudiantes usen algunas librerías para importar datos y luego aprendan algunos comandos de Pandas para analizar e inspeccionar los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Datos para los ejemplos\n",
    "\n",
    "Usaremos dos conjuntos de datos para este Notebook:\n",
    "<ol>\n",
    "<li>Datos de viajes en Taxi en la ciudad de Nueva York:</li>\n",
    "\n",
    "El proyecto <i>Open Data</i> de la Ciudad de Nueva York nos da acceso a una gran cantiadad de datos del quehacer de la ciudad. En este caso usaremos el sitio con los datos de viajes en Taxi, disponibles en https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page\n",
    "    \n",
    "En la carpeta '`data`' está disponible la base de datos de todos los viajes realizados en Mayo de 2024. El archivo se llama '`yellow_tripdata_2024-05.parquet`'.\n",
    "\n",
    "El formato PARQUET, que es open-source desarrollado por Apache, es un formato eficiente para almacenar y leer bases de datos de gran tamaño. Para poder leer este formato desde Python, deberán instalar una nueva librería llamada ' `pyarrow` '. Para instalarla use el comando:\n",
    "\n",
    "<code>> conda install pyarrow</code>\n",
    "    \n",
    "<li>Datos de casos de COVID en Chile:</li>\n",
    "\n",
    "Durante la pandemia, el Ministerio de Ciencia y Tecnología, con el apoyo de múltiples grupos de investigación y universidades, armó un repositorio abierto de datos sobre la situación de la pandemia en Chile. Los datos a utilizar en este ejemplo provienen del repositorio GitHub **Datos-COVID19** disponible en https://github.com/MinCiencia/Datos-COVID19. Estaremos usando el \n",
    "\n",
    "\"*Data Product 1 - Casos totales por comuna incremental: el archivo Covid-19.csv contiene las columnas 'Región', ‘Código Región’, 'Comuna', ‘Código comuna’, 'Población', múltiples columnas correspondientes a '[fecha]', y una columna 'Tasa'. Estas últimas columnas, ‘[fecha]’, contienen los 'Casos Confirmados' reportados por el Ministerio de Salud de Chile en cada una de las fechas que se indican en las respectivas columnas.*\" https://github.com/MinCiencia/Datos-COVID19/tree/master/output/producto1\n",
    "\n",
    "En la carpeta '`data`' está disponible la base de datos de todos los casos confirmados hasta enero de 2023.\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Librerías\n",
    "\n",
    "El trabajo de esta clase se centrará en el uso de NumPy y Pandas, pero necesitamos otras librerías adicionales para leer los datos y graficar información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Navegación en carpetas y acceso a datos\n",
    "\n",
    "Para improtar los archvios de datos, necesitamos identificar en qué directorio están guardados en nuestro sistema y en qué directorio estamos trabajando (\"working directory\").\n",
    "\n",
    "Algunos comandos importantes:\n",
    "- `%ls`: lista el contenido del directorio actual command lists all content in the current working directory.\n",
    "- `%cd 'subdirectorio'`: permite cambiar la ubicación actual a 'subdirectorio'\n",
    "- `%cd ..`: permite navegar hacia atrás al directorio superior del actual\n",
    "- `%pwd`: entrega la ruta del directorio actual\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Estudio de datos de viajes en NYC\n",
    "\n",
    "El objetivo de este ejercicio es entender cuántos viajes ocurrieron en la ciudad de Nueva York durante mayo de 2023 y cuáles son los lugares más relevantes para tomar pasajeros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Importar datos\n",
    "\n",
    "El primer paso será importar los datos, que están en un archivo en formato Parquet, y pasarlos a un DataFrame de Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leer la base parquet\n",
    "trips = pq.read_table('yellow_tripdata_2024-05.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 `pandas` y DataFrames\n",
    "\n",
    "El método `<x>.to_pandas()` permite transformar el archivo Parquet en un DataFrame de Pandas.\n",
    "Un DataFrame es una base de datos estructurada, que posee columnas y filas con la información relevante. Una referencia rápida a varias cosas que se pueden hacer con DataFrames está disponible acá: https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformar a dataframe de pandas\n",
    "trips = trips.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Leer e inspeccionar un DataFrame\n",
    "\n",
    "Un DataFrame de Pandas posee una serie de métodos que permiten revisar los datos contenidos en el DataFrame. Algunos de los más relevantes los vemos a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombres de las columnas\n",
    "trips.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtener los datos de una columna\n",
    "trips[\"trip_distance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtener una fila del DataFrame\n",
    "trips[\"trip_distance\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Contestando la pregunta\n",
    "\n",
    "A continuación haremos una serie de cálculos para contestar nuestra pregunta inicial: ¿Cuál es el mejor lugar en NYC para tomar pasajeros?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada columna de un DataFrame es una Serie, que corresponde a un arreglo 1-D con una etiqueta. Por lo tanto, en el caso de columnas con datos numéricos, podemos aplicar todas las operaciones matemáticas disponibles en `numpy`: https://numpy.org/doc/stable/reference/routines.math.html\n",
    "\n",
    "Partamos con la cantidad total de pasajeros que viajaron en Mayo de 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suma de la columna de pasajeros\n",
    "total_pasajeros = trips[\"passenger_count\"].sum()\n",
    "print(f'La cantidad total de pasajeros fue de {total_pasajeros}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora veamos esa suma por cada zona\n",
    "trips_by_loc = trips[[\"PULocationID\", \"passenger_count\"]].groupby(\"PULocationID\").sum()\n",
    "trips_by_loc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_loc = trips_by_loc.idxmax()\n",
    "max_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_by_loc.loc[max_loc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Era esperable el resultado?\n",
    "\n",
    "Acá pueden ver un mapa con el ID de los diferentes lugares:\n",
    "\n",
    "<img style=\"float: left; padding-right: 20px; width: 500px\" src=\"https://www.nyc.gov/assets/tlc/images/content/pages/about/taxi_zone_map_queens.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Estudio de datos de enfermos COVID\n",
    "\n",
    "El primer paso es importar los datos estructurados del CSV. Para ello, podemos usar una librería de NumPy que permite importar datos en formato CSV directamente.\n",
    "\n",
    "### 5.1 `numpy`: np.loadtxt() y np.genfromtxt()\n",
    "\n",
    "Numpy provee funciones para leer archivos de texto estructurado directamente como arreglos (`np.ndarray`). \n",
    "\n",
    "En primer lugar la función `np.loadtxt()`, permite cargar archivos cuyo contenido es solamente numérico. Generalmente trabajaremos con datasets que tienen distintos tipos de datos en distintas columnas; por ejemplo, strings y floats. En este caso, es necesario utilizar la función `np.genfromtxt()`, que puede manejar este tipo de datos. Si usamos como argumento `dtype=None`, la función infiere el tipo de datos de cada columna en forma automática.\n",
    "\n",
    "La documentación de ambas funciones se encuentra en: <br>\n",
    "- https://numpy.org/doc/stable/reference/generated/numpy.loadtxt.html\n",
    "- https://numpy.org/doc/stable/reference/generated/numpy.genfromtxt.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombre del archivo a leer\n",
    "data_file='Covid-19.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar el archivo\n",
    "data = np.loadtxt(data_file, delimiter=',',dtype='str')#skiprows=1\n",
    "\n",
    "# Algunas formas de explorar los datos:\n",
    "print(data[1])\n",
    "#print(data.shape)\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar data como floats y saltar la primera fila: data_float\n",
    "data = np.genfromtxt(data_file, delimiter=',', dtype=None, skip_header=1, encoding=None)\n",
    "\n",
    "print(data[0])\n",
    "print(data.shape)\n",
    "\n",
    "#numpy se las puede arreglar con datos mezclados pero es mejor pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general, `numpy` hace un buen trabajo identificando los tipos en conjuntos de datos con tipos mezclados, pero la librería natural para trabajar con datos estructurados es `pandas`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 `pandas`: read_csv para pasar a DataFrame\n",
    "\n",
    "La función `pd.read_csv()` permite leer un archivo de texto en formato CSV (comma separated value) y generar un DataFrame.\n",
    "El delimitador por defecto es la coma (,), pero también pueden leerse datasets con otros tipos de separación, especificando el parámetro `delimiter`.\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# leer los datos\n",
    "data = pd.read_csv(data_file, delimiter=',')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data['Region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Índices y acceso a información de celdas\n",
    "\n",
    "Al igual que en el caso de NYC, podemos acceder a datos específicos de la base en forma simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resumen de datos por comuna para un día en particular\n",
    "datos_resumen = data[['Comuna','26-12-2022']]\n",
    "datos_resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columna de un día en particular\n",
    "data['26-12-2022']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombre de las comunas\n",
    "data['Comuna']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtrar los datos para una comuna en particular\n",
    "data_macul = data[data['Comuna']=='Macul']\n",
    "data_macul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identificar las fechas disponibles\n",
    "columnas = data.columns[5:-1]\n",
    "columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sólo los datos de las columnas con fecha\n",
    "datos_enfermos = data[columnas]\n",
    "datos_enfermos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# información estadística por cada columna\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Operaciones con columnas\n",
    "\n",
    "Cada columna de un DataFrame es una Serie, que corresponde a un arreglo 1-D con una etiqueta. Por lo tanto, en el caso de columnas con datos numéricos, podemos aplicar todas las operaciones matemáticas disponibles en `numpy`:\n",
    "\n",
    "https://numpy.org/doc/stable/reference/routines.math.html\n",
    "\n",
    "También podemos realizar operaciones entre 2 o más columnas, o entre columnas y escalares.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcular la cantidad de casos por region\n",
    "enfermos_por_region = data.groupby(\"Region\").sum(numeric_only=True)\n",
    "# mostrar sólo los datos de enfermos\n",
    "enfermos_por_region[columnas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.plot(enfermos_por_region.loc['Maule'][columnas], 'x-', label='Maule')\n",
    "plt.plot(enfermos_por_region.loc['Magallanes'][columnas], 'x-', label='Magallanes')\n",
    "plt.legend()\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Casos Acumulados')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
